{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "teacher_forcing_ratio = 0.5\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\", 3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "#     s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"&apos;m\", r\"am\", s)\n",
    "    s = re.sub(r\"&apos;s\", r\"is\", s)\n",
    "    s = re.sub(r\"&apos;re\", r\"are\", s)\n",
    "    s = re.sub(r\"&apos;\", r\"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open('../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang)) as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open('../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang)) as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    input_lang = Lang(sourcelang)\n",
    "    output_lang = Lang(targetlang)\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88918\n",
      "en 69063\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6133\n",
      "en 4015\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5215\n",
      "en 3518\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% of chinese sentences length = 44.0\n",
      "95% of english sentences length = 48.0\n",
      "(['他们', '基本', '基本上', '是', '嗜', '肉', '的'], ['And', 'it', 'is', 'basically', 'a', 'meat', 'locker', ' .'])\n"
     ]
    }
   ],
   "source": [
    "print(\"95% of chinese sentences length = {0}\".format(np.percentile([len(x[0]) for x in pairs_tra], 95)))\n",
    "print(\"95% of english sentences length = {0}\".format(np.percentile([len(x[1]) for x in pairs_tra], 95)))\n",
    "print(random.choice(pairs_tra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 38\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputtensor': tensor([  49,  871,   16, 1235,  454, 1112,    6,   84,   85,  322,  398,  310,\n",
       "            6, 1236, 1237,  735,   57, 1238,  391,  621,  611,  612,  613,   84,\n",
       "           85,   16, 1239,   18,  885,    6, 1240,    1], device='cuda:0'),\n",
       " 'inputlen': 32,\n",
       " 'targettensor': tensor([ 48,  89,  52,  53, 577, 206,  77,  30, 113,  25,  54,  21, 210, 831,\n",
       "          21,  22,  23,  56,  77, 206,  52,  53, 921, 915,  44,   1],\n",
       "        device='cuda:0'),\n",
       " 'targetlen': 26}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    for datum in batch:        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "               torch.from_numpy(np.array(src_len)).to(device),torch.from_numpy(np.array(tar_len)).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence batch: \n",
      "tensor([[   16,  1878,   110,  ...,     2,     2,     2],\n",
      "        [  108,   375,    39,  ...,     2,     2,     2],\n",
      "        [ 5175,  5631,     6,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [ 2702,  6376,   208,  ...,     2,     2,     2],\n",
      "        [  416,  2147,  7549,  ...,     2,     2,     2],\n",
      "        [ 4713, 20335,    18,  ...,     2,     2,     2]], device='cuda:0')\n",
      "input batch dimension: torch.Size([64, 38])\n",
      "target sentence batch: \n",
      "tensor([[   61,   196,    89,  ...,  6946,    44,     1],\n",
      "        [  296,   570,  4043,  ...,     2,     2,     2],\n",
      "        [  918,  1687,   306,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [ 1556,   799,  1893,  ...,     2,     2,     2],\n",
      "        [  227,  1179, 12123,  ...,     2,     2,     2],\n",
      "        [  181,   296,   127,  ...,     2,     2,     2]], device='cuda:0')\n",
      "target batch dimension: torch.Size([64, 38])\n",
      "input sentence len: \n",
      "tensor([32,  7, 11, 10,  5, 38, 15,  9, 34, 15,  4,  7, 14, 12, 38, 29, 21, 20,\n",
      "         8, 10, 13, 31, 18,  8, 20,  8, 10,  6, 38, 19, 18, 22,  2, 18, 28, 38,\n",
      "         4, 13,  8, 19, 11,  7, 32, 26,  6,  8, 38, 17, 22,  8, 14,  6, 11, 14,\n",
      "        13,  8, 31,  9,  2, 32, 24,  6,  5,  7], device='cuda:0')\n",
      "target sentence len: \n",
      "tensor([38, 12,  9, 13,  6, 38, 16, 10, 38, 19,  7,  7, 16, 13, 38, 19, 31, 20,\n",
      "         9,  8, 19, 27, 19,  9, 22,  6, 12,  6, 38, 18, 18, 26,  4, 22, 32, 38,\n",
      "         7, 11,  7, 23, 12,  6, 38,  7, 12,  6, 38, 15, 22, 11, 13,  6, 11, 15,\n",
      "        11, 12, 34,  9,  4, 32, 19,  6,  6, 15], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample data loader\n",
    "count = 0\n",
    "for data in train_loader:\n",
    "    count+=1\n",
    "    print('input sentence batch: ')\n",
    "    print(data[0])\n",
    "    print('input batch dimension: {}'.format(data[0].size()))\n",
    "    print('target sentence batch: ')\n",
    "    print(data[1])\n",
    "    print('target batch dimension: {}'.format(data[1].size()))\n",
    "    print('input sentence len: ')\n",
    "    print(data[2])\n",
    "    print('target sentence len: ')\n",
    "    print(data[3])\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, n_layers = 1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional=False, batch_first = True) #in/out (batch, seq_len, feature_size)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device) \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size()[0]\n",
    "        seq_len = input.size()[1]\n",
    "        embedded = self.embedding(input).view(batch_size, seq_len, -1) \n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "            \n",
    "        hidden = self.fc(hidden).view(batch_size,-1,self.hidden_size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size \n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size,\n",
    "                                      embedding_dim = hidden_size)\n",
    "        self.gru = nn.GRU(input_size = hidden_size,\n",
    "                          hidden_size = hidden_size, \n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #input shape: B*S (s=1) * I \n",
    "        #print('in decoder, input dimension is {} '.format(input.size()))\n",
    "        input = input.view(-1,1)\n",
    "        batch_size = input.size()[0]\n",
    "        output = self.embedding(input).view(batch_size, 1, -1)\n",
    "        \n",
    "        hidden = hidden.view(1,batch_size,-1)\n",
    "        for i in range(self.n_layers):\n",
    "            #output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embedding = nn.Embedding(6,3)\n",
    "input_test = torch.LongTensor([[0,2,0,5]])\n",
    "print(input_test.size())\n",
    "embedding(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    batch_size = input_tensor.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_optimizer.zero_grad()  \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size()[1] \n",
    "    target_length = target_tensor.size()[1]\n",
    "    \n",
    "\n",
    "    loss = 0    \n",
    "    _, hidden = encoder(input_tensor, encoder_hidden)\n",
    "    \n",
    "    \n",
    "    decoder_input = torch.tensor([batch_size*[SOS_token]], device=device).view(batch_size,-1) \n",
    "    decoder_hidden = hidden.to(device)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "    # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            decoder_input = target_tensor[:,di] \n",
    "            temp_loss = criterion(decoder_output[:,-1,:], target_tensor[:,di])\n",
    "            loss += temp_loss  \n",
    "            ave_loss = loss.sum()/batch_size\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):            \n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            temp_loss = criterion(decoder_output[:,-1,:], target_tensor[:,di])\n",
    "            loss += temp_loss \n",
    "            ave_loss = loss.sum()/batch_size\n",
    "\n",
    "    ave_loss.backward()\n",
    "    \n",
    "    \n",
    "    encoder_optimizer.step()   # update parameters\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ave_loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zh1087/nlp_environment/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0m 58s (- -1m 1s), Epoch: [1/1], Step: [200/3335], Train Loss: 3.793084514015601\n",
      "Time: 1m 56s (- -2m 3s), Epoch: [1/1], Step: [400/3335], Train Loss: 3.655755680485775\n",
      "Time: 2m 54s (- -3m 5s), Epoch: [1/1], Step: [600/3335], Train Loss: 3.6043344859073057\n",
      "Time: 3m 53s (- -4m 7s), Epoch: [1/1], Step: [800/3335], Train Loss: 3.611127577329936\n",
      "Time: 4m 51s (- -5m 8s), Epoch: [1/1], Step: [1000/3335], Train Loss: 3.651359323200428\n",
      "Time: 5m 50s (- -6m 9s), Epoch: [1/1], Step: [1200/3335], Train Loss: 3.6314693400734317\n",
      "Time: 6m 49s (- -7m 10s), Epoch: [1/1], Step: [1400/3335], Train Loss: 3.5898175199408295\n",
      "Time: 7m 47s (- -8m 12s), Epoch: [1/1], Step: [1600/3335], Train Loss: 3.5151336428993636\n",
      "Time: 8m 46s (- -9m 13s), Epoch: [1/1], Step: [1800/3335], Train Loss: 3.559734149732088\n",
      "Time: 9m 44s (- -10m 15s), Epoch: [1/1], Step: [2000/3335], Train Loss: 3.630864528856782\n",
      "Time: 10m 43s (- -11m 16s), Epoch: [1/1], Step: [2200/3335], Train Loss: 4.033851859444067\n",
      "Time: 11m 41s (- -12m 18s), Epoch: [1/1], Step: [2400/3335], Train Loss: 3.760139711279618\n",
      "Time: 12m 40s (- -13m 20s), Epoch: [1/1], Step: [2600/3335], Train Loss: 3.6827529867071855\n",
      "Time: 13m 38s (- -14m 21s), Epoch: [1/1], Step: [2800/3335], Train Loss: 3.6828734146921236\n",
      "Time: 14m 37s (- -15m 23s), Epoch: [1/1], Step: [3000/3335], Train Loss: 3.645051026595267\n",
      "Time: 15m 35s (- -16m 24s), Epoch: [1/1], Step: [3200/3335], Train Loss: 3.6369904849403754\n",
      "[3.793084514015601, 3.655755680485775, 3.6043344859073057, 3.611127577329936, 3.651359323200428, 3.6314693400734317, 3.5898175199408295, 3.5151336428993636, 3.559734149732088, 3.630864528856782, 4.033851859444067, 3.760139711279618, 3.6827529867071855, 3.6828734146921236, 3.645051026595267, 3.6369904849403754]\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.01\n",
    "num_epoch = 1\n",
    "print_every = 200\n",
    "plot_every = 200\n",
    "\n",
    "encoder1 = EncoderRNN(source_tra.n_words,hidden_size, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, target_tra.n_words).to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder1.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(reduce = False) \n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "        input_tensor = input_sentences\n",
    "        target_tensor = target_sentences\n",
    "        loss = train(input_tensor, target_tensor, encoder1,\n",
    "                     decoder1, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        if i > 0 and i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}'.format(\n",
    "                timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                len(train_loader),print_loss_avg))\n",
    "\n",
    "        if i > 0 and i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "                \n",
    "    print(plot_losses)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

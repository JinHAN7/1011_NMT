{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "teacher_forcing_ratio = 1\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu import raw_corpus_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_ind(arr):\n",
    "    arr = arr.cpu().numpy()\n",
    "    batch_size = arr.shape[1]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if 1 in arr[:,i]:\n",
    "            ind = np.where(arr[:,i]== 1)[0][0]\n",
    "        \n",
    "            arr[:,i][:ind+1]=1\n",
    "            arr[:,i][ind+1:]=0\n",
    "        else:\n",
    "            arr[:,i]=1\n",
    "        \n",
    "    \n",
    "    return arr, np.count_nonzero(arr)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\", 3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "#     s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"&apos;m\", r\"am\", s)\n",
    "    s = re.sub(r\"&apos;s\", r\"is\", s)\n",
    "    s = re.sub(r\"&apos;re\", r\"are\", s)\n",
    "    s = re.sub(r\"&apos;\", r\"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open('../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang)) as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open('../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang)) as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    input_lang = Lang(sourcelang)\n",
    "    output_lang = Lang(targetlang)\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88918\n",
      "en 69063\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6133\n",
      "en 4015\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5215\n",
      "en 3518\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% of chinese sentences length = 44.0\n",
      "95% of english sentences length = 48.0\n",
      "(['晶体', '晶体管', '变得', '越来', '越来越', '小', '才', '使', '这', '一切', '得以', '实现', '而', '技术', '更是', '得益', '得益于', '益于', '于此'], ['Transistors', 'are', 'getting', 'smaller', 'to', 'allow', 'this', 'to', 'happen', ',', 'and', 'technology', 'has', 'really', 'benefitted', 'from', 'that', ' .'])\n"
     ]
    }
   ],
   "source": [
    "print(\"95% of chinese sentences length = {0}\".format(np.percentile([len(x[0]) for x in pairs_tra], 95)))\n",
    "print(\"95% of english sentences length = {0}\".format(np.percentile([len(x[1]) for x in pairs_tra], 95)))\n",
    "print(random.choice(pairs_tra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 45\n",
    "BATCH_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputtensor': tensor([  49,  871,   16, 1235,  454, 1112,    6,   84,   85,  322,  398,  310,\n",
       "            6, 1236, 1237,  735,   57, 1238,  391,  621,  611,  612,  613,   84,\n",
       "           85,   16, 1239,   18,  885,    6, 1240,    1], device='cuda:0'),\n",
       " 'inputlen': 32,\n",
       " 'targettensor': tensor([ 48,  89,  52,  53, 577, 206,  77,  30, 113,  25,  54,  21, 210, 831,\n",
       "          21,  22,  23,  56,  77, 206,  52,  53, 921, 915,  44,   1],\n",
       "        device='cuda:0'),\n",
       " 'targetlen': 26}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    for datum in batch:        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "               torch.from_numpy(np.array(src_len)).to(device),torch.from_numpy(np.array(tar_len)).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence batch: \n",
      "tensor([[ 953, 3265,   49,  ...,    2,    2,    2],\n",
      "        [  49,   15,  277,  ...,    2,    2,    2],\n",
      "        [2370,    6,  185,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [ 174, 2181,  100,  ..., 1339,   80, 1487],\n",
      "        [ 619,  141,  235,  ...,    2,    2,    2],\n",
      "        [ 354,  185,   15,  ...,    2,    2,    2]], device='cuda:0')\n",
      "input batch dimension: torch.Size([80, 45])\n",
      "target sentence batch: \n",
      "tensor([[ 156,  732,  707,  ...,    2,    2,    2],\n",
      "        [  51,  185,   48,  ...,    2,    2,    2],\n",
      "        [ 550,  446,  330,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [  51,   81,   23,  ...,   90,  548, 5080],\n",
      "        [ 879,  220,  417,  ...,    2,    2,    2],\n",
      "        [  74,  254,  203,  ...,    2,    2,    2]], device='cuda:0')\n",
      "target batch dimension: torch.Size([80, 45])\n",
      "input sentence len: \n",
      "tensor([ 9,  9, 25, 15, 31, 11, 36, 35, 45,  9,  5, 29,  9, 14, 18, 45, 16, 37,\n",
      "         7, 19, 11,  6, 28, 12, 15,  7, 23, 12, 20, 27, 15, 20,  4, 11, 45, 28,\n",
      "        38,  7, 22, 17, 15, 17, 14, 32, 15,  5, 35, 16, 16,  6, 16, 10, 35,  9,\n",
      "        26, 18, 10, 10,  8, 13, 24, 14, 26, 11, 11,  3,  9,  5, 45, 11,  4, 11,\n",
      "         6, 21, 13, 28,  9, 45, 13,  7], device='cuda:0')\n",
      "target sentence len: \n",
      "tensor([13, 12, 32,  7, 29, 14, 40, 45, 45,  8, 11, 29, 11, 12, 16, 45, 22, 42,\n",
      "        11, 20, 17,  8, 34,  9, 18,  9, 39, 13, 22, 28, 14, 20,  8, 11, 45, 41,\n",
      "        35,  8, 28, 24, 18, 21, 15, 41, 20,  9, 34, 19, 16,  8, 21, 13, 32,  9,\n",
      "        27, 24, 13, 14, 11, 13, 19, 15, 23, 13, 11,  7, 12,  6, 45, 14,  8, 16,\n",
      "        11, 31, 16, 30, 13, 45, 18,  8], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample data loader\n",
    "count = 0\n",
    "for data in train_loader:\n",
    "    count+=1\n",
    "    print('input sentence batch: ')\n",
    "    print(data[0])\n",
    "    print('input batch dimension: {}'.format(data[0].size()))\n",
    "    print('target sentence batch: ')\n",
    "    print(data[1])\n",
    "    print('target batch dimension: {}'.format(data[1].size()))\n",
    "    print('input sentence len: ')\n",
    "    print(data[2])\n",
    "    print('target sentence len: ')\n",
    "    print(data[3])\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, n_layers = 1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional=False, batch_first = True) #in/out (batch, seq_len, feature_size)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device) \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size()[0]\n",
    "        seq_len = input.size()[1]\n",
    "        embedded = self.embedding(input).view(batch_size, seq_len, -1) \n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "            \n",
    "        hidden = self.fc(hidden).view(batch_size,-1,self.hidden_size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size \n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size,\n",
    "                                      embedding_dim = hidden_size)\n",
    "        self.gru = nn.GRU(input_size = hidden_size,\n",
    "                          hidden_size = hidden_size, \n",
    "                          batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #input shape: B*S (s=1) * I \n",
    "        #print('in decoder, input dimension is {} '.format(input.size()))\n",
    "        input = input.view(-1,1)\n",
    "        batch_size = input.size()[0]\n",
    "        output = self.embedding(input).view(batch_size, 1, -1)\n",
    "        \n",
    "        hidden = hidden.view(1,batch_size,-1)\n",
    "        for i in range(self.n_layers):\n",
    "            #output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer):\n",
    "    \n",
    "    batch_size = input_tensor.size()[0]\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_optimizer.zero_grad()  \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size()[1] \n",
    "    target_length = target_tensor.size()[1]\n",
    "    \n",
    "\n",
    "    loss = 0    \n",
    "    _, hidden = encoder(input_tensor, encoder_hidden)\n",
    "    \n",
    "    \n",
    "    decoder_input = torch.tensor([batch_size*[SOS_token]], device=device).view(batch_size,-1) \n",
    "    decoder_hidden = hidden.to(device)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        loss = 0 \n",
    "        criterion = nn.NLLLoss(reduce = True, ignore_index = 2, reduction = 'mean') \n",
    "\n",
    "    # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            decoder_input = target_tensor[:,di] \n",
    "            temp_loss = criterion(decoder_output[:,-1,:], target_tensor[:,di])\n",
    "            loss += temp_loss \n",
    "            \n",
    "        ave_loss = loss/target_length\n",
    "                        \n",
    "    else:\n",
    "        loss = None \n",
    "        criterion = nn.NLLLoss(reduce = False) \n",
    "        prediction = None\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):            \n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "            if prediction is None:\n",
    "                prediction = topi.view(1,-1)\n",
    "            else:\n",
    "                prediction = torch.cat((prediction, topi.view(1,-1)), dim=0)            \n",
    "                            \n",
    "            temp_loss = criterion(decoder_output[:,-1,:], target_tensor[:,di])\n",
    "            \n",
    "            if loss is None:\n",
    "                loss = temp_loss.view(1,-1)\n",
    "            else:\n",
    "                loss = torch.cat((loss, temp_loss.view(1,-1)),dim=0)\n",
    "            \n",
    "       \n",
    "        mask, count = mask_ind(prediction)\n",
    "        total_loss = torch.sum(loss * torch.from_numpy(mask).float().to(device))\n",
    "        ave_loss = total_loss/count\n",
    "\n",
    "    ave_loss.backward()\n",
    "    \n",
    "    \n",
    "    encoder_optimizer.step()   # update parameters\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ave_loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx_2_sent_new(idx_tensor, lang_obj):\n",
    "    word_list = []\n",
    "    #truth_word_list = []\n",
    "    for i in idx_tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            word_list.append(lang_obj.index2word[i.item()])\n",
    "#     for j in truth_tensor:\n",
    "#         if j.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "#             truth_word_list.append(lang_obj.index2word[j.item()])\n",
    "    sent = (' ').join(word_list)\n",
    "    #truth_sent = (' ').join(truth_word_list)\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_new(corpus,truths):\n",
    "    n = len(corpus)\n",
    "    bleu = [0]*n\n",
    "    for i in range(n):\n",
    "        pred, true = corpus[i], truths[i]\n",
    "        pred_ls = [convert_idx_2_sent_new(sent, target_tra) for sent in pred]\n",
    "        true_ls = [convert_idx_2_sent_new(sent, target_tra) for sent in true]\n",
    "        bleu[i] = corpus_bleu(pred_ls, [true_ls]).score\n",
    "    return np.mean(bleu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, data_loader, max_length=MAX_SENT_LEN):\n",
    "    start = time.time()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    inputs = []\n",
    "    corpus = []\n",
    "    truths = []\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(data_loader):\n",
    "#         if i % 5 == 0:\n",
    "#             print('Time: {}, Step: [{}/{}]'.format(\n",
    "#                 timeSince(start, i + 1/len(train_loader)), i, len(data_loader)))\n",
    "        inputs.append(input_sentences.to(device))\n",
    "        input_tensor = input_sentences.to(device)\n",
    "        truths.append(target_sentences.to(device))\n",
    "        target_tensor = target_sentences.to(device) \n",
    "        #truths.append(target_tensor)\n",
    "        input_length = input_tensor.size()[1]\n",
    "        batch_size = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        #encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "        \n",
    "        \n",
    "        decoder_hidden = encoder_hidden.to(device)\n",
    "        decoder_input = torch.tensor([batch_size*[SOS_token]], device=device).view(batch_size,-1) \n",
    "        decoded_words = torch.zeros(batch_size, max_length)\n",
    "    \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            decoded_words[:,di] = topi.squeeze()\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        corpus.append(decoded_words)\n",
    "        #print(inputs[0].size(), corpus[0].size(), truths[0].size())\n",
    "    return inputs, corpus, truths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zh1087/nlp_environment/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2m 16s (- -3m 45s), Epoch: [1/5], Step: [100/2668], Train Loss: 3.226272175312042, BLEU: 0.2792153053314296\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict<  . Auctioneers acetic rendition semi-literate Rodrigo haranguing tantrums  . nudism gastronomy cut-grass nudism tectonically restitution tectonically epistemological Twelve Powell gizmo gizmo governor gizmo Vertes proportional propel snowflake Kulp gibberish restate restate transcendental sub-section restitution tectonically epistemological Whoosh Shyam prejudices restate million-pound 30-square-mile Marsalisly\n",
      "Time: 4m 31s (- -5m 30s), Epoch: [1/5], Step: [200/2668], Train Loss: 2.6513734745979307, BLEU: 0.30803700387774513\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict<  . dissociated 1,020  . Nessun assumed consummatory  . pro-bono Vermeulen Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Mecca Ultimately phalanx Wade Qutb Qutb C-clamp partner Wade Qutb JusticeMakers Ramirez mark example of course ,\n",
      "Time: 6m 46s (- -7m 15s), Epoch: [1/5], Step: [300/2668], Train Loss: 2.4496072363853454, BLEU: 0.3389442366340201\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< neediness  . So let is happening  . Mansion post-rational Weighs limiter inessential anorexia Nothing falsetto Trash confessions Portray  . Thanks depositors 80- raided Talons Terribus best-known  . He asks Galveston merciful foretaste Hebbian Papusay  . Thanks Canopied charters Misuse crushes Sergeant individual examination\n",
      "Time: 9m 1s (- -9m 0s), Epoch: [1/5], Step: [400/2668], Train Loss: 2.36921555519104, BLEU: 0.2939467695406982\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Garik MO  . gizmo separatists Benedictine diverting potluck  . Thanks cease-fire  ? Because Warrior Shouldn self-conscious  ? Because 101 Warrior  ? Because 101 all-powerful scabbing looser evenings  . Thanks depletive hair-like gimbals  . Thanks Waiting Dishes defied  . He asks t mean it\n",
      "Time: 11m 16s (- -12m 45s), Epoch: [1/5], Step: [500/2668], Train Loss: 2.270324983596802, BLEU: 0.29570237594517335\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< they behaved it turns out there  . Very three-month-old t mean it turns out there  . Some Advisor t mean  ? Because it turns out there  . Thanks Youngblood diverting  ? Because Elgin t seem like this problem  . Thank you know how much more\n",
      "Time: 13m 30s (- -14m 30s), Epoch: [1/5], Step: [600/2668], Train Loss: 2.202440786361694, BLEU: 0.28227423243961886\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< They were able to protect their own backyard  . Some Advisor  . Some EVE are going on top  . Everybody boldly  . At Dre Karate cold  ? Because Elgin t seem like this case  ? Because nobody is happening important thing  . Thanks dry-cleaning Debora\n",
      "Time: 15m 45s (- -16m 15s), Epoch: [1/5], Step: [700/2668], Train Loss: 2.191635708808899, BLEU: 0.2619052681254913\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Turn approved  ? Anyone  ? What do anything  ? What  ? Do  ? What  ? Because it looks like this picture  ? Bless prodder super-columns super-columns super-columns super-columns super-columns nudism super-columns nudism nudism nudism nudism nudism nudism nudism nudism nudism super-columns nudism nudism nudism\n",
      "Time: 18m 0s (- -18m 0s), Epoch: [1/5], Step: [800/2668], Train Loss: 2.147629791498184, BLEU: 0.21141390217796946\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Turn them together they behaved  . Remember  ! &quot; Look  ! &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Hey &quot; Yes  ! &quot; Hey &quot; Yes  ! &quot; Hey &quot; Yes\n",
      "Time: 20m 15s (- -21m 45s), Epoch: [1/5], Step: [900/2668], Train Loss: 2.102129944562912, BLEU: 0.2473592665802929\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Some of spades them up against the United States  . They don t worry about it falls  . Literally possesses it looks like this picture thing about it looks like this graph mite  . Literally Organize Valdez is happening here today is happening important thing\n",
      "Time: 22m 30s (- -23m 30s), Epoch: [1/5], Step: [1000/2668], Train Loss: 2.0591032683849333, BLEU: 0.27177002681796747\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Soldiers them up against the globe Ocean  . They are born useless  . Literally virginica  . . . gizmo prodder dry-cleaning encase three-time Shmulik exoteric Gerhard vexing anti-neutrino three-time torrenting torrenting ankles Brute odious tempers trucker double-object three-time Continue rawest Qutb ballerina Lifespring super-columns appendage Papusay\n",
      "Time: 24m 45s (- -25m 15s), Epoch: [1/5], Step: [1100/2668], Train Loss: 2.020078752040863, BLEU: 0.2722219716288614\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Same stunts sauce dollars per year ago  . Amazing virginica  . Amazing virginica  . Literally virginica  . . . Tough 18-wheelers 18-wheelers 18-wheelers eco-car 18-wheelers eco-car Mecca Mecca soul-crushing Mecca Mecca super-columns Mecca sultan Balasubramaniam Balasubramaniam Balasubramaniam Balasubramaniam Balasubramaniam Balasubramaniam coincides coincides coincides coincides coincides coincides\n",
      "Time: 27m 0s (- -27m 0s), Epoch: [1/5], Step: [1200/2668], Train Loss: 1.9786748337745665, BLEU: 0.25340272467739944\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< has been able to promote them down there amidst no longer whatsoever Ngu  . Amazing virginica  . . . Tough inquiry-based exoteric million-pound e-venture well-engineered retouches scatters GeV storylines Kneel penetrant bracing bracing definable criminologist criminologist criminologist criminologist half-hour Grandmothers , one-two-three Heather forty-five , albeit\n",
      "Time: 29m 15s (- -30m 45s), Epoch: [1/5], Step: [1300/2668], Train Loss: 1.9823860681056977, BLEU: 0.22441377634506293\n",
      "\n",
      "Input> 塔利 塔利班 走 了 父亲 大声 叫 着\n",
      "\n",
      "Target= &quot; The Taliban are gone  ! &quot; my father shouted  . \n",
      "Predict< Parents dollars per capita dollars per capita dollars per year year  . Here is been able to eradicate them up again  . Literally Organize Adrian it turns out loud natural-born gifting 2020 inches Fanning Aquarius for granted example minutes ago alaikum Shapers sells charlatans Gs\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 2000\n",
    "learning_rate = 0.0001\n",
    "num_epoch = 5\n",
    "print_every = 100\n",
    "plot_every = 100\n",
    "\n",
    "encoder1 = EncoderRNN(source_tra.n_words,hidden_size, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, target_tra.n_words).to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder1.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(reduce = False) \n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    \n",
    "    plot_bleu_score_val = []\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "        encoder1.train()\n",
    "        decoder1.train()\n",
    "        input_tensor = input_sentences\n",
    "        target_tensor = target_sentences\n",
    "        loss = train(input_tensor, target_tensor, encoder1,\n",
    "                     decoder1, encoder_optimizer, decoder_optimizer)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        if i > 0 and i % print_every == 0:\n",
    "            inputs, corpus, truths = evaluate(encoder1, decoder1, val_loader, max_length=MAX_SENT_LEN)\n",
    "            bleu_score_val_avg = bleu_new(corpus, truths)#np.mean(bleu_score_val)\n",
    "            plot_bleu_score_val.append(bleu_score_val_avg)\n",
    "\n",
    "\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}, BLEU: {}'.format(\n",
    "                timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                len(train_loader),print_loss_avg, bleu_score_val_avg))\n",
    "            print('\\nInput> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[0][3] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "            print('\\nTarget= %s'%(convert_idx_2_sent_new(truths[0][3], target_tra)),\n",
    "                    '\\nPredict< %s' %(convert_idx_2_sent_new(corpus[0][3], target_tra)))\n",
    "        if i > 0 and i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "                \n",
    "    print(plot_losses)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

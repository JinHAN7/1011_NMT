{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Beam search  \n",
    "- self-attention  \n",
    "- EOS mask loss\n",
    "//////\n",
    "- CNN - done\n",
    "- plot - done\n",
    "- BLEU - done\n",
    "-  Evaluation - done\n",
    "- early stopping - done\n",
    "-  GPU - done\n",
    "- Batch encoder - done\n",
    "- pretrained wordvec/dataloader- done\n",
    "- sort in collate_func - done\n",
    "- save best model - done\n",
    "\n",
    "\n",
    "\n",
    "To run this notebook for actual analysis:  \n",
    "remove breaker in train_model  \n",
    "increase hidden size  \n",
    "increase eva_every  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "import os\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import sacrebleu\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import time\n",
    "import math\n",
    "from sacrebleu import corpus_bleu\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "VOCAB_SIZE = 80000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_loader(file_name):\n",
    "    with open(file_name+'.p', 'rb') as f:\n",
    "        objct = pkl.load(f)\n",
    "    return(objct)\n",
    "\n",
    "def pkl_dumper(obj, file_name):\n",
    "    with open(file_name+'.p', 'wb') as f:\n",
    "        pkl.dump(obj, f, protocol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_wordvec(lan):\n",
    "    if lan == 'zh':\n",
    "        filename = 'wiki.zh.vec'\n",
    "    elif lan == 'en':\n",
    "        filename = 'wiki-news-300d-1M.vec'\n",
    "    else:\n",
    "        filename = 'wiki-news-300d-1M.vec' #######\n",
    "    with open(os.path.join(data_dir, filename)) as f:\n",
    "        word_vecs = np.zeros((VOCAB_SIZE+4, 300))\n",
    "        word_vecs[UNK_IDX] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[SOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "        word_vecs[EOS_token] = np.random.normal(scale=0.6, size=(300, ))\n",
    "\n",
    "        words_ft = {'<pad>': PAD_IDX,\n",
    "                   '<unk>': UNK_IDX, \n",
    "                   '<sos>': SOS_token,\n",
    "                   '<eos>': EOS_token}\n",
    "        idx2words_ft = {PAD_IDX:'<pad>', UNK_IDX: '<unk>', SOS_token: '<sos>', EOS_token: '<eos>'}\n",
    "        ordered_words_ft = ['<sos>', '<eos>', '<pad>', '<unk>']\n",
    "        count = 0\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if len(idx2words_ft) >= VOCAB_SIZE: \n",
    "                break\n",
    "            s = line.split()\n",
    "            if (np.asarray(s[1:]).size != 300):\n",
    "                print(lan, i, np.asarray(s[1:]).size)\n",
    "                continue\n",
    "            word_vecs[count+4, :] = np.asarray(s[1:])\n",
    "            words_ft[s[0]] = count+4\n",
    "            idx2words_ft[count+4] = s[0]\n",
    "            ordered_words_ft.append(s[0])\n",
    "            count += 1\n",
    "    word_vecs = torch.FloatTensor(word_vecs)\n",
    "    pkl_dumper(word_vecs, os.path.join(data_dir, lan + '_word_vecs'))\n",
    "    pkl_dumper(words_ft, os.path.join(data_dir, lan + '_words_ft'))\n",
    "    pkl_dumper(idx2words_ft, os.path.join(data_dir, lan + '_idx2words_ft'))\n",
    "    pkl_dumper(ordered_words_ft, os.path.join(data_dir, lan + '_ordered_words_ft'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained_wordvec('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_pretrained_wordvec('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = {}\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "word_vecs['en'] = pkl_loader(data_dir+'/en_word_vecs')\n",
    "word_vecs['zh'] = pkl_loader(data_dir+'/zh_word_vecs')\n",
    "word2index['en'] = pkl_loader(data_dir+'/en_words_ft')\n",
    "word2index['zh'] = pkl_loader(data_dir+'/zh_words_ft')\n",
    "index2word['en'] = pkl_loader(data_dir+'/en_idx2words_ft')\n",
    "index2word['zh'] = pkl_loader(data_dir+'/zh_idx2words_ft')\n",
    "# en_ordered_words_ft = pkl_loader('data/en_ordered_words_ft')\n",
    "# zh_ordered_words_ft = pkl_loader('data/zh_ordered_words_ft')\n",
    "VOCAB_SIZE = len(word2index['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 80000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index['en']), len(word2index['zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3958, '知识')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2index['en']['apple'], index2word['en'][10397]\n",
    " word2index['zh']['知识'], index2word['zh'][word2index['zh']['知识']]\n",
    "# index2word['en'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name, index2word, word2index):\n",
    "        self.name = name\n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(index2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "def normalizeString(s):\n",
    "#     s = re.sub(r\"&apos;m\", r\"am\", s)\n",
    "#     s = re.sub(r\"&apos;t\", r\"not\", s)\n",
    "#     s = re.sub(r\"&apos;s\", r\"is\", s)\n",
    "#     s = re.sub(r\"&apos;re\", r\"are\", s)\n",
    "#     s = re.sub(r\"&quot;\", r\"\", s)\n",
    "#     s = re.sub(r\"&apos;ve\", r\"have\", s)\n",
    "#     s = re.sub(r\"&apos;d\", r\"had\", s)\n",
    "#     s = re.sub(r\"&apos;\", r\"\", s)\n",
    "\n",
    "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = html.unescape(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It 's true .\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString('It &apos;s true .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang)) as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open(data_dir+'/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang)) as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    pairs = [pair for pair in pairs if ((len(pair[0])>0)and(len(pair[1])>0))]\n",
    "    pairs.sort(key=lambda x: len(x[0]))\n",
    "#     print(pairs[:10])\n",
    "    chunk_size = math.ceil(len(pairs) / BATCH_SIZE)\n",
    "    chunks = [pairs[i:i + chunk_size] for i in range(0, len(pairs), chunk_size)]\n",
    "    first_chunks = chunks[:-1]\n",
    "    last_chunk = chunks[-1]\n",
    "    random.shuffle(first_chunks)\n",
    "    chunks = first_chunks+[last_chunk]\n",
    "    pairs = [pair for chunk in chunks for pair in chunk]\n",
    "    \n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    if sourcelang == 'zh':\n",
    "        input_lang = Lang(sourcelang, index2word['zh'], word2index['zh'])\n",
    "    else:\n",
    "        input_lang = Lang(sourcelang, index2word['zh'], word2index['zh']) ####\n",
    "    output_lang = Lang(targetlang, index2word['en'], word2index['en'])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counted words:\n",
      "zh 80000\n",
      "en 80000\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counted words:\n",
      "zh 80000\n",
      "en 80000\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counted words:\n",
      "zh 80000\n",
      "en 80000\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% of chinese sentences length = 68.40000000000009\n",
      "99% of english sentences length = 75.40000000000009\n",
      "(['Remi', '知道', '什么', '是', '爱'], ['Remi', 'knows', 'what', 'love', 'is', '.'])\n"
     ]
    }
   ],
   "source": [
    "print(\"99% of chinese sentences length = {0}\".format(np.percentile([len(x[0]) for x in pairs_val], 99)))\n",
    "print(\"99% of english sentences length = {0}\".format(np.percentile([len(x[1]) for x in pairs_val], 99)))\n",
    "print(random.choice(pairs_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    \n",
    "    for datum in batch: \n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    \n",
    "    max_length = [np.max(src_len), np.max(tar_len)]\n",
    "    for datum in batch: \n",
    "        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0, max_length[0]-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0,max_length[1]-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        \n",
    "        \n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    tar_data = np.array(tar_data)[ind_dec_order]\n",
    "    tar_len = np.array(tar_len)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "                torch.LongTensor(np.array(src_len)).to(device),torch.LongTensor(np.array(tar_len)).to(device)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_func)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence batch: \n",
      "tensor([[ 1085,  1585, 14037,  ...,     3,   532,     1],\n",
      "        [ 1323,  1735,  1790,  ...,   580,  7532,     1],\n",
      "        [ 1346, 25109,  7880,  ...,     6,  6776,     1],\n",
      "        ...,\n",
      "        [  160,   136,   738,  ...,  6213, 10286,     1],\n",
      "        [17040,    99,    20,  ...,     3,  4298,     1],\n",
      "        [  160,   811,     3,  ...,  1539,   973,     1]], device='cuda:0')\n",
      "input batch dimension: torch.Size([64, 20])\n",
      "target sentence batch: \n",
      "tensor([[ 170,  705,   17,  ...,    2,    2,    2],\n",
      "        [1784,    4,   34,  ...,    2,    2,    2],\n",
      "        [ 369,   95,   36,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [ 170,   32, 1341,  ...,    2,    2,    2],\n",
      "        [ 519,   97, 8314,  ...,    2,    2,    2],\n",
      "        [ 170,   45,   32,  ...,    2,    2,    2]], device='cuda:0')\n",
      "target batch dimension: torch.Size([64, 34])\n",
      "input sentence len: \n",
      "tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20], device='cuda:0')\n",
      "target sentence len: \n",
      "tensor([29, 19, 29, 17, 32, 26, 34, 25, 16, 22, 16, 18, 20, 22, 23, 16, 21, 17,\n",
      "        15, 26, 11, 17, 27, 29, 24, 25, 20, 22, 21, 17, 20, 25, 28, 22, 12, 20,\n",
      "        23, 20, 23, 20, 26, 24, 31, 21, 27, 23, 20, 30, 29, 24, 20, 27, 24, 22,\n",
      "        33, 20, 27, 23, 19, 16, 26, 21, 25, 24], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample data loader\n",
    "count = 0\n",
    "for data in train_loader:\n",
    "    count+=1\n",
    "    print('input sentence batch: ')\n",
    "    print(data[0])\n",
    "    print('input batch dimension: {}'.format(data[0].size()))\n",
    "    print('target sentence batch: ')\n",
    "    print(data[1])\n",
    "    print('target batch dimension: {}'.format(data[1].size()))\n",
    "    print('input sentence len: ')\n",
    "    print(data[2])\n",
    "    print('target sentence len: ')\n",
    "    print(data[3])\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['而',\n",
       " '耕地',\n",
       " '在',\n",
       " '地球',\n",
       " '上',\n",
       " '是',\n",
       " '十分',\n",
       " '<unk>',\n",
       " '的',\n",
       " '第二',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '不要',\n",
       " '和',\n",
       " '粮食',\n",
       " '<unk>',\n",
       " '作物',\n",
       " '抢',\n",
       " '地',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[source_tra.index2word[i.item()] for i in data[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Because',\n",
       " 'crops',\n",
       " 'are',\n",
       " 'already',\n",
       " 'growing',\n",
       " 'on',\n",
       " 'that',\n",
       " 'land',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'very',\n",
       " 'scarce',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[target_tra.index2word[i.item()] for i in data[1][3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    'HIDDEN_SIZE': 500,\n",
    "    'LR': 0.001,\n",
    "    'EVA_EVERY': 200,\n",
    "    'DROP_OUT': 0,\n",
    "    'TEACHER_RATIO': 0.9,\n",
    "    'N_LAYERS': 2,\n",
    "    'KER_SIZE': 3,\n",
    "    'NUM_EPOCHS': 10   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, emb_size=300, word_vec=None):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if len(word_vec) > 0:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "            \n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional=True) \n",
    "        self.fc1 = nn.Linear(2*hidden_size, hidden_size)\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device) \n",
    "    \n",
    "    def forward(self, input, lengths, hidden):\n",
    "        input = input.transpose(0,1)\n",
    "        batch_size, seq_len = input.size()\n",
    "        embedded = self.embedding(input).view(seq_len, batch_size, -1)\n",
    "        embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths)#max_len*batch\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output) \n",
    "        output = self.fc1(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, emb_size=300, word_vec=None, ker_size=3, dropout_p=0.5):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if len(word_vec) > 0:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, emb_size, padding_idx=PAD_IDX)\n",
    "          \n",
    "          \n",
    "        self.seq = nn.Sequential(nn.Conv1d(emb_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool1d(kernel_size=ker_size, stride=1, padding=(ker_size-1)//2))\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, lengths, hidden):\n",
    "        input = input.transpose(0,1)\n",
    "        batch_size, seq_len = input.size()\n",
    "        # input size for conv1d is , N is a batch size, C denotes a number of channels, L is a length of signal sequence.\n",
    "        output = self.embedding(input).view(batch_size, -1, seq_len)\n",
    "        output = self.seq(output)\n",
    "        output = output.view(seq_len, batch_size, -1) \n",
    "        output = self.fc(output)\n",
    "        output = F.relu(self.dropout(output))\n",
    "        output = self.fc(output)\n",
    "        hidden = torch.nn.functional.max_pool1d(output.view(batch_size, -1, seq_len), seq_len).permute(2, 0, 1)\n",
    "        # output seq_len, batch_size, hidden\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, emb_size=300, dropout_p=0.1, word_vec=None, max_length=MAX_SENT_LEN):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        if len(word_vec) > 0:\n",
    "            self.embedding = nn.Embedding(output_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(output_size, emb_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.combine = nn.Linear(self.hidden_size + self.emb_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # encoder_outputs [80, 64, 500]\n",
    "        input = input.view(1,-1)\n",
    "        seq_len, batch_size = input.size()\n",
    "        output = self.embedding(input).view(1, batch_size, -1)\n",
    "#         print(output[0].size(), encoder_outputs[-1].size())\n",
    "        output = torch.cat((output[0], encoder_outputs[-1]), 1)\n",
    "#         print(output.size()) #64, 800\n",
    "        output = self.combine(output).unsqueeze(0)\n",
    "#         print(output.size()) #1, 64, 500\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, emb_size=300, dropout_p=0.1, word_vec=None, max_length=MAX_SENT_LEN):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "        if len(word_vecs) > 0:\n",
    "            self.embedding = nn.Embedding(output_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vec)\n",
    "            self.embedding.requires_grad = False\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(output_size, emb_size, padding_idx=PAD_IDX)\n",
    "            \n",
    "        self.attn = nn.Linear(self.hidden_size + self.emb_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size + self.emb_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        input = input.view(1,-1)\n",
    "        batch_size = input.size()[1]\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)  \n",
    "#         print(attn_weights.unsqueeze(1).size())\n",
    "#         print(encoder_outputs.transpose(0,1))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs.transpose(0,1))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied.transpose(0,1)[0]), 1)\n",
    "        \n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "#         print(output.size())\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_ind(arr):\n",
    "    arr = arr.cpu().numpy()\n",
    "    batch_size = arr.shape[1]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if 1 in arr[:,i]:\n",
    "            ind = np.where(arr[:,i]== 1)[0][0]\n",
    "            arr[:,i][:ind+1]=1\n",
    "            arr[:,i][ind+1:]=0\n",
    "        else:\n",
    "            arr[:,i]=1\n",
    "    return arr, np.count_nonzero(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, input_len, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, mode_dec=None, mode_enc=None, max_length=MAX_SENT_LEN):\n",
    "    \n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size()[0]\n",
    "    target_length = target_tensor.size()[0]\n",
    "    batch_size = input_tensor.size()[1]\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device) \n",
    "#     print('encoder_outputs size:', encoder_outputs.size())\n",
    "    loss = 0\n",
    "    \n",
    "    # feed-forward layer resulting encoder outputs, ei refers to each word token in input sentence\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, input_len, encoder_hidden)\n",
    "    if encoder_outputs.size()[0] < max_length:\n",
    "        encoder_outputs = torch.cat((encoder_outputs, torch.zeros(max_length- encoder_outputs.size()[0], batch_size, encoder_outputs.size()[2]).to(device)))\n",
    "#     print('encoder_outputs size:', encoder_outputs.size()) # # 32, 64, 500\n",
    "    if mode_enc == 'cnn':\n",
    "        encoder_hidden = nn.Linear(hidden_size,hidden_size)(encoder_hidden[0].cpu()).to(device).unsqueeze(0)\n",
    "    else:\n",
    "        encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "            torch.cat((encoder_hidden[0].cpu(),encoder_hidden[1].cpu()),dim = 1)).to(device).unsqueeze(0)\n",
    "#     print('encoder_hidden size:', encoder_hidden.size()) # 1, 64, 500\n",
    "# #     print(\"t:\", encoder_hidden.dtype)\n",
    "    decoder_hidden = encoder_hidden.to(device)\n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  \n",
    "#     #print('input to decoder:', decoder_input.size(), decoder_hidden.size(), encoder_outputs.size())\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        loss = 0 \n",
    "        criterion = nn.NLLLoss(ignore_index=PAD_IDX, reduction = 'elementwise_mean')\n",
    "        for di in range(target_length):\n",
    "            if mode_dec == 'attn':\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                \n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_tensor[di]  \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "        ave_loss = loss/target_length\n",
    "    else:\n",
    "        loss = None \n",
    "        criterion = nn.NLLLoss(reduce = False) \n",
    "        prediction = None\n",
    "  \n",
    "        for di in range(target_length):\n",
    "            if mode_dec == 'attn':\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            if prediction is None:\n",
    "                prediction = topi.view(1,-1)\n",
    "            else:\n",
    "                prediction = torch.cat((prediction, topi.view(1,-1)), dim=0)\n",
    "                \n",
    "            decoder_input = topi.transpose(0,1).detach()\n",
    "            \n",
    " \n",
    "            #decoder_input = topi.squeeze().detach()\n",
    "    \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            if loss is None:\n",
    "                loss = temp_loss.view(1,-1)\n",
    "            else:\n",
    "                loss = torch.cat((loss, temp_loss.view(1,-1)),dim=0)\n",
    "                \n",
    "        mask, count = mask_ind(prediction)\n",
    "        total_loss = torch.sum(loss * torch.from_numpy(mask).float().to(device))\n",
    "        ave_loss = total_loss/count\n",
    "\n",
    "    ave_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=3)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=3)\n",
    "    encoder_optimizer.step() \n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ave_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx_2_sent(idx_tensor, lang_obj):\n",
    "    word_list = []\n",
    " \n",
    "    for i in idx_tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            word_list.append(lang_obj.index2word[i.item()])\n",
    "\n",
    "    sent = (' ').join(word_list)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(corpus,truths):\n",
    "    n = len(corpus)\n",
    "    bleu = [0]*n\n",
    "    for i in range(n):\n",
    "        pred, true = corpus[i], truths[i]\n",
    "        pred_ls = [convert_idx_2_sent(sent, target_tra) for sent in pred]\n",
    "        true_ls = [convert_idx_2_sent(sent, target_tra) for sent in true]\n",
    "        bleu[i] = corpus_bleu(pred_ls, [true_ls]).score\n",
    "    return np.mean(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, data_loader, mode_enc, mode_dec, max_length=MAX_SENT_LEN):\n",
    "    start = time.time()\n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    inputs = []\n",
    "    corpus = []\n",
    "    truths = []\n",
    "    for i, (input_sentences, target_sentences, input_len, target_len) in enumerate(data_loader):\n",
    "#         if i % 5 == 0:\n",
    "#             print('Time: {}, Step: [{}/{}]'.format(\n",
    "#                 timeSince(start, i + 1/len(train_loader)), i, len(data_loader)))\n",
    "        inputs.append(input_sentences.to(device))\n",
    "        input_tensor = input_sentences.transpose(0,1).to(device)\n",
    "        truths.append(target_sentences.to(device))\n",
    "        target_tensor = target_sentences.transpose(0,1).to(device) \n",
    "        input_length = input_tensor.size()[0]\n",
    "        batch_size = input_tensor.size()[1]\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, input_len, encoder_hidden)\n",
    "        \n",
    "        if encoder_outputs.size()[0] < max_length:\n",
    "            encoder_outputs = torch.cat((encoder_outputs, torch.zeros(max_length - encoder_outputs.size()[0], batch_size, encoder_outputs.size()[2]).to(device)))\n",
    "        \n",
    "        if mode_enc == 'cnn':\n",
    "            encoder_hidden = nn.Linear(hidden_size,hidden_size)(encoder_hidden[0].cpu()).to(device).unsqueeze(0)\n",
    "        else:\n",
    "            encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "            torch.cat((encoder_hidden[0].cpu(),encoder_hidden[1].cpu()),dim = 1)).to(device).unsqueeze(0)\n",
    "\n",
    "        decoder_hidden = encoder_hidden.to(device)\n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device) \n",
    "        decoded_words = torch.zeros(batch_size, max_length)\n",
    "    \n",
    "        for di in range(max_length):\n",
    "            if mode_dec == 'attn':\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "#             print(decoded_words.size())\n",
    "            decoder_input = topi.transpose(0,1).detach()\n",
    "            decoded_words[:,di] = topi.squeeze()\n",
    "        corpus.append(decoded_words)\n",
    "        #print(inputs[0].size(), corpus[0].size(), truths[0].size())\n",
    "    return inputs, corpus, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_bleu(bleu_score,\n",
    "                losses):\n",
    "    \n",
    "    batches = np.arange(0, len(bleu_score))\n",
    "    f, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax1 = axs[0]\n",
    "    ax1.plot(batches, losses, label='Validation loss')\n",
    "    ax1.set_xlabel(\"number of batches\")\n",
    "#     ax1.plot(batches, validation_loss_history, alpha=0.7, label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2 = axs[1]\n",
    "    ax2.plot(batches, bleu_score, label='Validation BLEU Score')\n",
    "    ax2.set_xlabel(\"number of batches\")\n",
    "#     ax2.plot(batches, validation_acc_history, alpha=0.7, label='Validation Accuracy')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(mode_enc, mode_dec, hyper, start_epoch=0):\n",
    "    start = time.time()\n",
    "    hidden_size = hyper['HIDDEN_SIZE']\n",
    "    learning_rate = hyper['LR']\n",
    "    eva_every = hyper['EVA_EVERY']\n",
    "    dropout_p = hyper['DROP_OUT']\n",
    "    teacher_forcing_ratio = hyper['TEACHER_RATIO']\n",
    "    n_layers = hyper['N_LAYERS']\n",
    "    ker_size = hyper['KER_SIZE']\n",
    "    num_epoch = hyper['NUM_EPOCHS']\n",
    "    early_stopping = False\n",
    "    patience = 3\n",
    "    required_progress = 0.01\n",
    "    \n",
    "    if mode_enc == 'rnn':\n",
    "        encoder = EncoderRNN(source_tra.n_words, hidden_size, word_vec=word_vecs[source_tra.name]).to(device)\n",
    "        \n",
    "    else:\n",
    "        encoder = EncoderCNN(source_tra.n_words, hidden_size, word_vec=word_vecs[source_tra.name], dropout_p=dropout_p, ker_size=ker_size).to(device)\n",
    "       \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    encoder_scheduler = ExponentialLR(encoder_optimizer, gamma=0.95)\n",
    "    \n",
    "    if mode_dec == 'attn':\n",
    "            decoder = AttnDecoder(hidden_size, target_tra.n_words, word_vec=word_vecs[target_tra.name], dropout_p=dropout_p).to(device)\n",
    "    else:\n",
    "            decoder = Decoder(hidden_size, target_tra.n_words, word_vec=word_vecs[target_tra.name], dropout_p=dropout_p).to(device)\n",
    "            \n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    decoder_scheduler = ExponentialLR(decoder_optimizer, gamma=0.95) \n",
    "    plot_bleu_score_val = []\n",
    "    plot_losses = []\n",
    "    loss_total = 0 \n",
    "    best_score = None\n",
    "    count = 0\n",
    "    filename = 'best' #########\n",
    "    for epoch in range(1, num_epoch + 1): \n",
    "        for i, (input_sentences, target_sentences, input_len, target_len) in enumerate(train_loader): \n",
    "            ### delete break\n",
    "\n",
    "            encoder.train()\n",
    "            decoder.train()\n",
    "            input_tensor = input_sentences.transpose(0,1).to(device)    \n",
    "            target_tensor = target_sentences.transpose(0,1).to(device)\n",
    "            loss = train(input_tensor, input_len, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, mode_dec=mode_dec, mode_enc=mode_enc)\n",
    "            loss_total += loss\n",
    "            if i > 0 and i % eva_every == 0:\n",
    "                    inputs, corpus, truths = evaluate(encoder, decoder, val_loader, max_length=MAX_SENT_LEN, mode_enc=mode_enc, mode_dec=mode_dec)\n",
    "                    bleu_score_val = bleu(corpus, truths)\n",
    "                    bleu_score_val_avg = np.mean(bleu_score_val)\n",
    "                    loss_avg = loss_total / eva_every\n",
    "                    loss_total = 0\n",
    "                    plot_losses.append(loss_avg)\n",
    "                    plot_bleu_score_val.append(bleu_score_val_avg)\n",
    "                    if best_score is None:\n",
    "                        best_score = bleu_score_val_avg\n",
    "                    if bleu_score_val_avg < best_score + required_progress:\n",
    "                        count += 1\n",
    "                    elif bleu_score_val_avg > best_score:\n",
    "                        state = {'epoch': start_epoch + epoch + 1, \n",
    "                                 'state_dict_enc': encoder.state_dict(),\n",
    "                                 'state_dict_dec': decoder.state_dict(), \n",
    "                                 'best_accuracy': best_score, \n",
    "                                 'optimizer_enc': encoder_optimizer.state_dict(),\n",
    "                                'optimizer_dec': decoder_optimizer.state_dict()}\n",
    "                        print ('new best achieved')\n",
    "                        torch.save(state, filename+'.pth.tar')\n",
    "                        best_score = bleu_score_val_avg\n",
    "                        count = 0\n",
    "                    if early_stopping:\n",
    "                        if count >= patience:\n",
    "                            print(\"earily stop triggered\")\n",
    "                            break\n",
    "                    print('-----------------------------------------')\n",
    "                    print('Time: {0}, Epoch: [{1}/{2}], Step: [{3}/{4}], Train Loss: {5}, BLEU score: {6}'.format(\n",
    "                        timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                        len(train_loader), loss_avg, bleu_score_val_avg))\n",
    "                    print('\\nInput> %s'%(' '.join([source_tra.index2word[i.item()] for i in inputs[0][3] if i.item() not in set([PAD_IDX,EOS_token,SOS_token])])))\n",
    "                    print('\\nTarget= %s'%(convert_idx_2_sent(truths[0][3], target_tra)),\n",
    "                    '\\nPredict< %s' %(convert_idx_2_sent(corpus[0][3], target_tra)))\n",
    "                    print('-----------------------------------------')\n",
    "        \n",
    "        if early_stopping:\n",
    "            if count >= patience:\n",
    "                break\n",
    "    plot_loss_bleu(plot_bleu_score_val, plot_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN+Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('rnn', 'attn', hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rnn+noattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('rnn', 'noattn', hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn+attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('cnn', 'attn', hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn+noattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('cnn', 'noattn', hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each team will build the following sequence of neural translation systems for two language pairs, Vietnamese (Vi)→English (En) and Chinese (Zh)→En (prepared corpora will be provided):\n",
    "\n",
    "Recurrent neural network based encoder-decoder without attention\n",
    "Recurrent neural network based encoder-decoder with attention\n",
    "Replace the recurrent encoder with either convolutional or self-attention based encoder.\n",
    "[Optional] Build either or both fully self-attention translation system or/and multilingual translation system.\n",
    "\n",
    "You are expected to implement these on your own (if necessary), experiment them with both language pairs, report their performance (measured in terms of automatic evaluation metrics) and analyze their behaviours and properties.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"UNK\", 3:\"PAD\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "def normalizeString(s):\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = html.unescape(s)\n",
    "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"&apos;m\", r\"am\", s)\n",
    "#     s = re.sub(r\"&apos;s\", r\"is\", s)\n",
    "#     s = re.sub(r\"&apos;re\", r\"are\", s)\n",
    "#     s = re.sub(r\"&apos;\", r\"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open('data/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang)) as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open('data/iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang)) as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    input_lang = Lang(sourcelang)\n",
    "    output_lang = Lang(targetlang)\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88918\n",
      "en 69126\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6133\n",
      "en 4018\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5215\n",
      "en 3523\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% of chinese sentences length = 44.0\n",
      "95% of english sentences length = 48.0\n",
      "(['你', '乘坐', '俄国', '的', '飞行', '飞行器', '飞行', '这', '是', '可以', '的', '因为', '苏联', '的', '太空', '计划', '缺乏', '资金', '一个', '座位', '可以', '得到', '两千', '两千万', '千万', '万美金', '美金', '对', '他们', '来说', '很', '不错'], ['You', 'can', 'fly', 'with', 'Russian', 'hardware', ' .', 'This', 'is', 'available', 'because', 'a', 'Russian', 'space', 'program', 'is', 'starving', ',', 'and', 'it', \"'s\", 'nice', 'for', 'them', 'to', 'get', '20', 'million', 'here', 'and', 'there', 'to', 'take', 'one', 'of', 'the', 'seats', ' .'])\n"
     ]
    }
   ],
   "source": [
    "# Hu\n",
    "print(\"95% of chinese sentences length = {0}\".format(np.percentile([len(x[0]) for x in pairs_tra], 95)))\n",
    "print(\"95% of english sentences length = {0}\".format(np.percentile([len(x[1]) for x in pairs_tra], 95)))\n",
    "print(random.choice(pairs_tra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs) #Hu\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_val, target_val, pairs_val)\n",
    "test_data = NMTDataset(source_tes, target_tes, pairs_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213377"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    for datum in batch:        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "        \n",
    "        ### Hu Modified\n",
    "    ind_dec_order = np.argsort(src_len)[::-1]\n",
    "    src_data = np.array(src_data)[ind_dec_order]\n",
    "    src_len = np.array(src_len)[ind_dec_order]\n",
    "    tar_data = np.array(tar_data)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(src_data)),torch.from_numpy(np.array(tar_data)),\n",
    "               torch.LongTensor(np.array(src_len)),torch.LongTensor(np.array(tar_len))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=False,collate_fn=collate_func)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence batch: \n",
      "target sentence batch: \n",
      "tensor([[   52,    49,   244,  ...,   169,    21,     6],\n",
      "        [  298,  1094,   773,  ...,   657,    21,  1949],\n",
      "        [  328,   115,   674,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [  158,     6,  1591,  ...,     2,     2,     2],\n",
      "        [  148, 14298,   215,  ...,     2,     2,     2],\n",
      "        [   52,   115,  1444,  ...,     2,     2,     2]])\n",
      "input sentence len: \n",
      "tensor([50, 50, 40, 36, 36, 35, 34, 32, 31, 28, 26, 26, 25, 23, 22, 21, 20, 17,\n",
      "        16, 13, 12, 11, 10, 10, 10,  9,  9,  8,  8,  7,  7,  6])\n",
      "target sentence len: \n",
      "tensor([33, 30,  9, 21, 38,  6, 36,  7,  9, 50, 19, 20, 13, 13,  8, 29, 23, 40,\n",
      "         6, 13,  9, 50, 26, 11, 16,  9, 11, 12, 33, 45, 39, 36])\n"
     ]
    }
   ],
   "source": [
    "# sample data loader\n",
    "for data in train_loader:\n",
    "    print('input sentence batch: ')\n",
    "    print('target sentence batch: ')\n",
    "    print(data[1])\n",
    "    print('input sentence len: ')\n",
    "    print(data[2])\n",
    "    print('target sentence len: ')\n",
    "    print(data[3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, \n",
    "                 vocab_size, dropout, bidirection = True, word_vecs = None):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirection == True:\n",
    "            self.directions = 2\n",
    "        else: \n",
    "            self.directions = 1\n",
    "        if word_vecs == None:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_size,padding_idx=PAD_IDX)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vecs)\n",
    "            self.embedding.requires_grad = False\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True, \n",
    "                          dropout=dropout, bidirectional=bidirection)\n",
    "\n",
    "    def forward(self, enc_input, lengths):\n",
    "        # do we need pack padded\n",
    "        batch_size, seq_len = enc_input.size() #seq_len will be used in cnn\n",
    "        self.hidden = self.initHidden(batch_size)\n",
    "        embedded = self.embedding(encoder_input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output = torch.nn.utils.rnn.pack_padded_sequence(output, lengths, batch_first=True)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        if self.directions == 2:\n",
    "            hidden = torch.cat((hidden[0], hidden[1]), dim = 1)\n",
    "        return output, hidden \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers * self.directions, batch_size,\n",
    "                            self.hidden_size, self.hidden_size, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, emb_size, hidden_size, num_layers, dropout, bidirection = True, word_vecs = None):\n",
    "        # output_size is the traget vocab size\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = num_layers\n",
    "        if bidirection == True:\n",
    "            self.directions = 2\n",
    "        else: \n",
    "            self.directions = 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD_IDX)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True, \n",
    "                          dropout=dropout, bidirectional=bidirection)\n",
    "        \n",
    "        self.out = nn.Linear(self.directions * hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, dec_input, hidden):\n",
    "        output = self.embedding(dec_input).view(1, 1, -1)\n",
    "        for i in range(self.num_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        if self.directions == 2:\n",
    "            hidden = torch.cat((hidden[0], hidden[1]), dim = 1)\n",
    "        output = output.squeeze(0)\n",
    "        output = self.softmax(self.out(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers * self.directions, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, num_classes,\n",
    "                 dropout, bidirection = True, word_vecs = None):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, hidden_size)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        if bidirection == True:\n",
    "            self.directions = 2\n",
    "        else: \n",
    "            self.directions = 1\n",
    "    \n",
    "    def forward(self, dec_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(dec_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        ##############################\n",
    "        # TODO: Implement Attention  #\n",
    "        ##############################\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((word_embedded[0], last_hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            output = F.relu(output)\n",
    "#             output = torch.nn.utils.rnn.pack_padded_sequence(output, lengths, batch_first=True)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        if self.directions == 2:\n",
    "            hidden = torch.cat((hidden[0], hidden[1]), dim = 1)\n",
    "\n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(output))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, ker_size,\n",
    "                 vocab_size, dropout, word_vecs = None):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if word_vecs == None:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "            self.embedding.weight = nn.Parameter(word_vecs)\n",
    "            self.embedding.requires_grad = False\n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=ker_size, padding=(ker_size-1)//2)\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, enc_input, lengths):\n",
    "        # do we need pack padded\n",
    "        batch_size, seq_len = enc_input.size() #seq_len will be used in cnn\n",
    "        embedded = self.embedding(encoder_input).view(1, 1, -1)\n",
    "        hidden = self.conv1(embedded.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden_p.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden_p.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "        hidden = torch.nn.functional.max_pool1d(hidden.transpose(1,2), enc_input.size()[-1]).transpose(1,2)\n",
    "        hidden = self.linear1(hidden)\n",
    "        hidden = F.relu(self.dropout(hidden))\n",
    "        hidden = self.linear2(hidden)\n",
    "        return hidden, hidden # to use the same training model, need two outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draft:  \n",
    "Beam search reference: https://github.com/IBM/pytorch-seq2seq/blob/master/seq2seq/models/TopKDecoder.py  \n",
    "BLEU score: https://github.com/MaximumEntropy/Seq2Seq-PyTorch/blob/master/evaluate.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_SENT_LEN):\n",
    "#     encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    model.eval()\n",
    "    for i, (p, h, lengths_p, lengths_h, labels) in enumerate(loader):\n",
    "        p_batch, h_batch, length_batch_p, length_batch_h, label_batch = p, h, lengths_p, lengths_h, labels\n",
    "        outputs = F.softmax(model(p_batch, h_batch, length_batch_p, length_batch_h), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels.size(0)\n",
    "        loss += F.cross_entropy(outputs, labels).detach().numpy()\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return np.round((100 * correct / total), 4), np.round(loss / i, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(validation_acc_history,\n",
    "                validation_loss_history,\n",
    "                train_acc_history,\n",
    "                train_loss_history):\n",
    "    \n",
    "    batches = np.arange(0, len(validation_acc_history))\n",
    "    f, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax1 = axs[0]\n",
    "    ax1.plot(batches, train_loss_history, label='Training loss')\n",
    "    ax1.set_xlabel(\"number of batches\")\n",
    "    ax1.plot(batches, validation_loss_history, alpha=0.7, label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2 = axs[1]\n",
    "    ax2.plot(batches, train_acc_history, label='Training Accuracy')\n",
    "    ax2.set_xlabel(\"number of batches\")\n",
    "    ax2.plot(batches, validation_acc_history, alpha=0.7, label='Validation Accuracy')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import pickle as pkl\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from sacrebleu import corpus_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "teacher_forcing_ratio = 0.5\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_IDX = 2\n",
    "UNK_IDX = 3\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\", 3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "#     s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"&apos;m\", r\"am\", s)\n",
    "    s = re.sub(r\"&apos;s\", r\"is\", s)\n",
    "    s = re.sub(r\"&apos;re\", r\"are\", s)\n",
    "    s = re.sub(r\"&apos;\", r\"\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingLangs(sourcelang, targetlang, setname):\n",
    "    input_ls = []\n",
    "    output_ls = []\n",
    "    print('Reading lines...')\n",
    "    # Read the file \n",
    "    with open('../../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,sourcelang)) as f:\n",
    "        for line in f.readlines():\n",
    "            input_ls.append([normalizeString(word) for word in line.split()])\n",
    "    with open('../../iwslt-%s-%s/%s.tok.%s'%(sourcelang, targetlang, setname,targetlang)) as f:\n",
    "        for line in f.readlines():\n",
    "            output_ls.append([normalizeString(word) for word in line.split()])\n",
    "    pairs = list(zip(input_ls, output_ls))\n",
    "    print('Read %s sentence pairs'%(len(input_ls)))\n",
    "    input_lang = Lang(sourcelang)\n",
    "    output_lang = Lang(targetlang)\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213377 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88918\n",
      "en 69063\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6133\n",
      "en 4015\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5215\n",
      "en 3518\n"
     ]
    }
   ],
   "source": [
    "source_tra, target_tra, pairs_tra = loadingLangs('zh', 'en', 'train')\n",
    "source_val, target_val, pairs_val = loadingLangs('zh', 'en', 'dev')\n",
    "source_tes, target_tes, pairs_tes = loadingLangs('zh', 'en', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% of chinese sentences length = 44.0\n",
      "95% of english sentences length = 48.0\n",
      "(['一直', '以为', '我们', '全力', '全力以赴'], ['We', 'have', 'been', 'working', 'very', 'hard', ' .'])\n"
     ]
    }
   ],
   "source": [
    "print(\"95% of chinese sentences length = {0}\".format(np.percentile([len(x[0]) for x in pairs_tra], 95)))\n",
    "print(\"95% of english sentences length = {0}\".format(np.percentile([len(x[1]) for x in pairs_tra], 95)))\n",
    "print(random.choice(pairs_tra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 38\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair,source,target):\n",
    "    input_lang = source\n",
    "    output_lang = target\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0]).reshape((-1))\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1]).reshape((-1))\n",
    "    return (input_tensor, input_tensor.shape[0], target_tensor, target_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, source, target, pairs):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        inp_ten, inp_len, tar_ten, tar_len = tensorsFromPair(self.pairs[key], self.source, self.target)\n",
    "        item = {}\n",
    "        item['inputtensor'] = inp_ten[:MAX_SENT_LEN]\n",
    "        item['inputlen'] = min(inp_len, MAX_SENT_LEN)\n",
    "        item['targettensor'] = tar_ten[:MAX_SENT_LEN]\n",
    "        item['targetlen'] = min(tar_len, MAX_SENT_LEN)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NMTDataset(source_tra, target_tra, pairs_tra)\n",
    "val_data = NMTDataset(source_tra, target_tra, pairs_val)\n",
    "test_data = NMTDataset(source_tra, target_tra, pairs_tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputtensor': tensor([  49,  871,   16, 1235,  454, 1112,    6,   84,   85,  322,  398,  310,\n",
       "            6, 1236, 1237,  735,   57, 1238,  391,  621,  611,  612,  613,   84,\n",
       "           85,   16, 1239,   18,  885,    6, 1240,    1], device='cuda:0'),\n",
       " 'inputlen': 32,\n",
       " 'targettensor': tensor([ 48,  89,  52,  53, 577, 206,  77,  30, 113,  25,  54,  21, 210, 831,\n",
       "          21,  22,  23,  56,  77, 206,  52,  53, 921, 915,  44,   1],\n",
       "        device='cuda:0'),\n",
       " 'targetlen': 26}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate function\n",
    "\n",
    "def collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    src_data, tar_data, src_len, tar_len = [], [], [], []\n",
    "    for datum in batch:        \n",
    "        src_datum = np.pad(np.array(datum['inputtensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['inputlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        tar_datum = np.pad(np.array(datum['targettensor']),\n",
    "                                pad_width=((0,MAX_SENT_LEN-datum['targetlen'])),\n",
    "                                mode=\"constant\", constant_values=PAD_IDX)\n",
    "        src_data.append(src_datum)\n",
    "        tar_data.append(tar_datum)\n",
    "        src_len.append(datum['inputlen'])\n",
    "        tar_len.append(datum['targetlen'])\n",
    "    return [torch.from_numpy(np.array(src_data)).to(device),torch.from_numpy(np.array(tar_data)).to(device),\n",
    "               torch.from_numpy(np.array(src_len)).to(device),torch.from_numpy(np.array(tar_len)).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence batch: \n",
      "tensor([[  108,   137,  5063,  ...,   101, 15985, 10313],\n",
      "        [ 4586,    31,  5194,  ...,     2,     2,     2],\n",
      "        [   49,   234,  3732,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [19409, 85798,  3719,  ...,     2,     2,     2],\n",
      "        [  108,  1222,  6346,  ...,     2,     2,     2],\n",
      "        [ 1100,   889,   263,  ...,   416,   571,     6]], device='cuda:0')\n",
      "input batch dimension: torch.Size([64, 38])\n",
      "target sentence batch: \n",
      "tensor([[  296,   840,   130,  ...,    21,   628,    56],\n",
      "        [   74, 24117,   446,  ...,     2,     2,     2],\n",
      "        [   51,     6,  3111,  ...,     2,     2,     2],\n",
      "        ...,\n",
      "        [ 6399,     5,  2062,  ...,     2,     2,     2],\n",
      "        [  296,   127,    21,  ...,     2,     2,     2],\n",
      "        [  442,    21,  6559,  ...,     6,   809,   232]], device='cuda:0')\n",
      "target batch dimension: torch.Size([64, 38])\n",
      "input sentence len: \n",
      "tensor([38, 22, 15, 38, 32, 19, 17, 14,  4, 18, 24, 18, 27,  8, 11, 18, 23, 13,\n",
      "        14, 14, 18, 26, 38, 11,  8, 20, 24, 19,  7,  4, 22, 38, 28, 30, 22, 21,\n",
      "         6, 38, 16, 10, 10,  9,  6, 20,  6,  8, 38, 15, 11, 18, 28, 38, 15, 14,\n",
      "        17, 10,  7,  8, 25, 12, 22, 11, 26, 38], device='cuda:0')\n",
      "target sentence len: \n",
      "tensor([38, 21, 17, 38, 29, 19, 13, 17,  7, 24, 21, 35, 26, 10, 12, 23, 22, 17,\n",
      "        11, 12, 20, 28, 38, 14,  9, 18, 22, 19, 11,  7, 24, 38, 29, 33, 21, 18,\n",
      "        12, 38, 21, 11, 13,  7,  6, 19,  7, 11, 36, 17, 12, 18, 31, 35, 14, 17,\n",
      "        14, 13, 11,  5, 24,  8, 25, 11, 27, 38], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sample data loader\n",
    "count = 0\n",
    "for data in train_loader:\n",
    "    count+=1\n",
    "    print('input sentence batch: ')\n",
    "    print(data[0])\n",
    "    print('input batch dimension: {}'.format(data[0].size()))\n",
    "    print('target sentence batch: ')\n",
    "    print(data[1])\n",
    "    print('target batch dimension: {}'.format(data[1].size()))\n",
    "    print('input sentence len: ')\n",
    "    print(data[2])\n",
    "    print('target sentence len: ')\n",
    "    print(data[3])\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers = 1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True) \n",
    "        self.fc1 = nn.Linear(2*hidden_size, hidden_size)\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device) \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size()[1]\n",
    "        seq_len = input.size()[0]\n",
    "        embedded = self.embedding(input).view(seq_len, batch_size, -1) \n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.fc1(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_SENT_LEN):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        input = input.view(1,-1)\n",
    "        batch_size = input.size()[1]\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)  \n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs.transpose(0,1))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied.transpose(0,1)[0]), 1)\n",
    "        \n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion, mask = None):\n",
    "    batch_size = input_tensor.size()[1]\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_optimizer.zero_grad()  \n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size()[0] \n",
    "    target_length = target_tensor.size()[0]\n",
    "    encoder_outputs = torch.zeros(target_length, batch_size, encoder.hidden_size, device=device) \n",
    "\n",
    "  \n",
    "    loss = 0\n",
    "    \n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "        torch.cat((encoder_hidden[0].cpu().data,encoder_hidden[1].cpu().data),dim = 1)).to(device).unsqueeze(0)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "    decoder_hidden = encoder_hidden.to(device)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            decoder_input = target_tensor[di]  \n",
    "            \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            loss += temp_loss * mask[di:di+1].float()  \n",
    "            ave_loss = loss.sum()/batch_size\n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "           \n",
    "\n",
    "            decoder_input = topi.transpose(0,1).detach()  # detach from history as input\n",
    "            \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            loss += temp_loss * mask[di:di+1].float()\n",
    "            ave_loss = loss.sum()/batch_size  \n",
    "            \n",
    "    ave_loss.backward()\n",
    "    \n",
    "    \n",
    "    encoder_optimizer.step()   \n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ave_loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zh1087/nlp_environment/py3.6.3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1m 2s (- -2m 58s), Epoch: [1/10], Step: [200/3335], Train Loss: 4.739537032277959\n",
      "Time: 2m 6s (- -3m 53s), Epoch: [1/10], Step: [400/3335], Train Loss: 4.64297931871916\n",
      "Time: 3m 5s (- -4m 54s), Epoch: [1/10], Step: [600/3335], Train Loss: 4.466100435758895\n",
      "Time: 4m 4s (- -5m 55s), Epoch: [1/10], Step: [800/3335], Train Loss: 4.562434840955235\n",
      "Time: 5m 4s (- -6m 56s), Epoch: [1/10], Step: [1000/3335], Train Loss: 4.546772529200506\n",
      "Time: 6m 3s (- -7m 57s), Epoch: [1/10], Step: [1200/3335], Train Loss: 4.6004956616853425\n",
      "Time: 7m 2s (- -8m 58s), Epoch: [1/10], Step: [1400/3335], Train Loss: 4.653946384630705\n",
      "Time: 8m 1s (- -9m 59s), Epoch: [1/10], Step: [1600/3335], Train Loss: 4.650428693670978\n",
      "Time: 9m 0s (- -10m 59s), Epoch: [1/10], Step: [1800/3335], Train Loss: 4.489596788506759\n",
      "Time: 9m 59s (- -10m 0s), Epoch: [1/10], Step: [2000/3335], Train Loss: 4.481733059130217\n",
      "Time: 10m 59s (- -11m 0s), Epoch: [1/10], Step: [2200/3335], Train Loss: 4.453929485521815\n",
      "Time: 11m 59s (- -12m 0s), Epoch: [1/10], Step: [2400/3335], Train Loss: 4.475480125828794\n",
      "Time: 12m 58s (- -13m 1s), Epoch: [1/10], Step: [2600/3335], Train Loss: 4.492378774944105\n",
      "Time: 13m 58s (- -14m 2s), Epoch: [1/10], Step: [2800/3335], Train Loss: 4.511610547115927\n",
      "Time: 14m 57s (- -15m 2s), Epoch: [1/10], Step: [3000/3335], Train Loss: 4.516339854190223\n",
      "Time: 15m 56s (- -16m 3s), Epoch: [1/10], Step: [3200/3335], Train Loss: 4.531958975540963\n",
      "[4.739537032277959, 4.64297931871916, 4.466100435758895, 4.562434840955235, 4.546772529200506, 4.6004956616853425, 4.653946384630705, 4.650428693670978, 4.489596788506759, 4.481733059130217, 4.453929485521815, 4.475480125828794, 4.492378774944105, 4.511610547115927, 4.516339854190223, 4.531958975540963]\n",
      "Time: 17m 36s (- -18m 29s), Epoch: [2/10], Step: [200/3335], Train Loss: 4.574930984095524\n",
      "Time: 18m 35s (- -19m 26s), Epoch: [2/10], Step: [400/3335], Train Loss: 4.554428431862278\n",
      "Time: 19m 35s (- -20m 26s), Epoch: [2/10], Step: [600/3335], Train Loss: 4.5532776762309854\n",
      "Time: 20m 34s (- -21m 26s), Epoch: [2/10], Step: [800/3335], Train Loss: 4.592414245605467\n",
      "Time: 21m 34s (- -22m 27s), Epoch: [2/10], Step: [1000/3335], Train Loss: 4.603099188553657\n",
      "Time: 22m 33s (- -23m 27s), Epoch: [2/10], Step: [1200/3335], Train Loss: 4.61033055154901\n",
      "Time: 23m 32s (- -24m 28s), Epoch: [2/10], Step: [1400/3335], Train Loss: 4.67156725632517\n",
      "Time: 24m 32s (- -25m 28s), Epoch: [2/10], Step: [1600/3335], Train Loss: 4.619485164441562\n",
      "Time: 25m 31s (- -26m 29s), Epoch: [2/10], Step: [1800/3335], Train Loss: 4.626092848526804\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "learning_rate=0.01\n",
    "num_epoch = 10\n",
    "print_every=200\n",
    "plot_every=200\n",
    "\n",
    "encoder1 = EncoderRNN(source_tra.n_words,hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, target_tra.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(attn_decoder1.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(reduce = False) \n",
    "\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  \n",
    "    plot_loss_total = 0  \n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "#         print(i)\n",
    "        input_tensor = input_sentences.transpose(0,1)   \n",
    "        target_tensor = target_sentences.transpose(0,1)\n",
    "        mask = target_tensor.ge(1)   \n",
    "        loss = train(input_tensor, target_tensor, encoder1,\n",
    "                     attn_decoder1, encoder_optimizer, decoder_optimizer, criterion, mask = mask)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if i > 0 and i % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}'.format(\n",
    "                timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                len(train_loader),print_loss_avg))\n",
    "\n",
    "        if i > 0 and i % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    print(plot_losses)\n",
    "\n",
    "        #if i % print_every == 0:\n",
    "            #corpus, truths = evaluate_rnn(encoder1, attn_decoder1, val_loader, max_length=MAX_SENT_LEN)\n",
    "            #score_ls = bleu(corpus, truths)\n",
    "            #avg_score = np.array(score_ls).mean()\n",
    "            #print_loss_avg = print_loss_total / print_every\n",
    "            #print_loss_total = 0\n",
    "            #print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}, Average BLEU: {}'.format(\n",
    "                    #timeSince(start, i + 1/len(train_loader)), epoch, num_epoch, i, \n",
    "                    #len(train_loader),print_loss_avg, avg_score))\n",
    "\n",
    "        #if i > 0 and i % plot_every == 0:\n",
    "            #plot_loss_avg = plot_loss_total / plot_every\n",
    "            #plot_losses.append(plot_loss_avg)\n",
    "            #plot_loss_total = 0\n",
    "\n",
    "                \n",
    "    #print(plot_losses)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rnn(encoder, decoder, data_loader, max_length=MAX_SENT_LEN):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    corpus = []\n",
    "    truths = []\n",
    "\n",
    "    for i, (input_sentences, target_sentences,len1,len2) in enumerate(data_loader): \n",
    "#         print('v',i)\n",
    "        input_tensor = input_sentences.transpose(0,1).to(device)  \n",
    "        target_tensor = target_sentences.to(device)\n",
    "        truths.append(target_tensor)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        batch_size = input_tensor.size()[1]\n",
    "#         print(batch_size)\n",
    "\n",
    "    # encode the source lanugage\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "        encoder_outputs = Variable(torch.zeros(max_length,batch_size, encoder.hidden_size)).to(device)\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] =  encoder_output[0]\n",
    "        encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "        torch.cat((encoder_hidden[0],encoder_hidden[1]),dim = 1)).unsqueeze(0)\n",
    "        \n",
    "    # decode the context vector\n",
    "        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]*batch_size])).to(device) # SOS\n",
    "#         print(decoder_input.size()) #[1,32]\n",
    "        # output of this function\n",
    "        decoded_words = torch.zeros(batch_size, max_length)\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        # unfold\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # hint: print out decoder_output and decoder_attention\n",
    "#             decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi\n",
    "        \n",
    "            decoded_words[:,di] = ni.squeeze()\n",
    "\n",
    "#             # stop unfolding whenever '<EOS>' token is returned\n",
    "#             if ni == EOS_token:\n",
    "#                 decoded_words.append('<EOS>')\n",
    "#                 break\n",
    "#             else:\n",
    "#                 decoded_words.append(target_tra.index2word[ni])\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor(ni.transpose(0,1))).to(device)\n",
    "#             print(decoded_words.size())\n",
    "        corpus.append(decoded_words)\n",
    "#             attns.append(decoder_attentions[:di + 1])\n",
    "    #truths = [t.transpose(0,1) for t in truths]\n",
    "    return corpus, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx_2_sent(pred_tensor, truth_tensor,lang_obj):\n",
    "    pred_word_list = []\n",
    "    truth_word_list = []\n",
    "    for i in pred_tensor:\n",
    "        if i.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            pred_word_list.append(lang_obj.index2word[i.item()])\n",
    "    for j in truth_tensor:\n",
    "        if j.item() not in set([PAD_IDX,EOS_token,SOS_token]):\n",
    "            truth_word_list.append(lang_obj.index2word[j.item()])\n",
    "    pred_sent = (' ').join(pred_word_list)\n",
    "    truth_sent = (' ').join(truth_word_list)\n",
    "    return pred_sent, truth_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(corpus, truths):\n",
    "    '''\n",
    "    corpus: list, NBs * BATCHSIZE * MAX_LEN\n",
    "    truths: list, NBs * BATCHSIZE * MAX_LEN\n",
    "    \n",
    "    return: array of length NBs, avg blue score for each batch\n",
    "    '''\n",
    "    n = len(corpus)\n",
    "    bleus = [0]*n\n",
    "    for i in range(n):\n",
    "        pred, true = corpus[i], truths[i]\n",
    "        sumbleu = 0.0\n",
    "        for j in range(len(corpus[i])):\n",
    "            pred_tensor, true_tensor = pred[j], true[j]\n",
    "            pred_sent, true_sent = convert_idx_2_sent(pred_tensor, true_tensor, target_tra)\n",
    "            sumbleu += corpus_bleu(true_sent, pred_sent).score\n",
    "        avgbleu = sumbleu / len(corpus[i])\n",
    "#         print(avgbleu)\n",
    "        bleus[i] = avgbleu\n",
    "    return bleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
